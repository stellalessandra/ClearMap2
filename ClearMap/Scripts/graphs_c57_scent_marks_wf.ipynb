{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph analysis for c57 mice reared with father exposed to scent marks\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook performs various analyses on cell count data from different experimental groups. The primary tasks include:\n",
    "\n",
    "1. **Loading Data**: Importing and cleaning cell count data.\n",
    "2. **Statistical Analysis**: Performing statistical tests to identify significant areas.\n",
    "3. **Graph Creation**: Generating and visualizing graphs based on correlation matrices.\n",
    "4. **Data Visualization**: Creating histograms, boxplots, and other visualizations to analyze data distributions.\n",
    "\n",
    "## Detailed Steps\n",
    "\n",
    "**1. Load Data**\n",
    "\n",
    "The notebook begins by loading and cleaning the volumes data using a custom function. It also loads results from a file and organizes experimental groups based on the subjects.\n",
    "\n",
    "**2. Define Parameters**\n",
    "\n",
    "- **Correlation Threshold**: A threshold for filtering correlations.\n",
    "- **Significant Areas**: Areas that show statistically significant differences based on predefined criteria.\n",
    "\n",
    "**3. Calculate Values Across Groups**\n",
    "\n",
    "Cell counts are computed across different experimental groups using specific functions that aggregate the data.\n",
    "\n",
    "**4. Cross-Correlation and Save Results**\n",
    "\n",
    "Cross-correlation matrices are computed for different experimental conditions (e.g., control, fam, unfam). Results are saved as CSV files for further analysis.\n",
    "\n",
    "**5. Create Graphs**\n",
    "\n",
    "Graphs are generated from the correlation matrices. The notebook uses functions to create and visualize these graphs, showing relationships between significant areas.\n",
    "\n",
    "**6. Plot Graphs**\n",
    "\n",
    "Graphs are plotted using various layouts to visualize the connections between significant areas. The layout used is a spring layout, which helps in visualizing the structure of the network.\n",
    "\n",
    "**7. Histogram and Boxplot Analysis**\n",
    "\n",
    "Histograms and boxplots are created to analyze the distribution of graph degrees and correlation values. This helps in understanding the statistical properties of the data.\n",
    "\n",
    "**8. Betweenness Centrality Analysis**\n",
    "\n",
    "Betweenness centrality is calculated for the graphs to identify key nodes within the network. This analysis is used to determine the relative importance of nodes in terms of their connectivity within the graph.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:38:35.587304Z",
     "start_time": "2024-09-16T09:38:34.390594Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from yaml import Loader\n",
    "import numpy as np\n",
    "import analyze_cells_energy as ace\n",
    "import utils\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "import networkx as nx\n",
    "import copy\n",
    "import itertools\n",
    "from utils_graphs import create_graph, plot_graph, get_colors, fig_graph_degrees\n",
    "import utils_PLS as upls\n",
    "import matplotlib.colors as cm\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:38:36.017705Z",
     "start_time": "2024-09-16T09:38:35.592136Z"
    }
   },
   "outputs": [],
   "source": [
    "# load query file where we added volumes for each area\n",
    "volumes = ace.clean_volumes_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:38:36.046225Z",
     "start_time": "2024-09-16T09:38:36.020033Z"
    }
   },
   "outputs": [],
   "source": [
    "dict_results_across_mice = np.load('dict_results/newvolumes/dict_results_across_mice_c57_scent_marks_wf.npy', \n",
    "                                   allow_pickle=True).item()\n",
    "subjects = list(dict_results_across_mice.keys())\n",
    "experimental_groups = utils.divide_in_exp_groups(list_subjects=subjects)\n",
    "batch='c57_scent_marks_wf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:38:36.053193Z",
     "start_time": "2024-09-16T09:38:36.047954Z"
    }
   },
   "outputs": [],
   "source": [
    "corr_threshold = 0.75\n",
    "allen_order = list(volumes[volumes['st_level']==8]['acronym'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:38:40.346233Z",
     "start_time": "2024-09-16T09:38:36.056211Z"
    }
   },
   "outputs": [],
   "source": [
    "df_levels = upls.create_df_levels(volumes, level=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis on number of cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:38:42.145255Z",
     "start_time": "2024-09-16T09:38:40.347392Z"
    }
   },
   "outputs": [],
   "source": [
    "significant_areas = ace.select_significant_areas(dictionary=dict_results_across_mice, \n",
    "                                             experimental_groups=experimental_groups, \n",
    "                                             batch=batch,\n",
    "                                             test='mannwhitneyu', \n",
    "                                             threshold_test=0.05,\n",
    "                                             threshold_pls=2.56,\n",
    "                                             value_test='n_cells', \n",
    "                                             value_pls='relative_density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:38:42.176397Z",
     "start_time": "2024-09-16T09:38:42.153147Z"
    }
   },
   "outputs": [],
   "source": [
    "df_control_cell_count, df_fam_cell_count, df_unfam_cell_count = \\\n",
    "ace.calculate_value_across_groups(experimental_groups=experimental_groups, \n",
    "                              dict_results_across_mice=dict_results_across_mice, \n",
    "                              value='n_cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:38:42.249902Z",
     "start_time": "2024-09-16T09:38:42.178943Z"
    }
   },
   "outputs": [],
   "source": [
    "df = ace.cross_corr(df_control_cell_count.set_index('area').loc[list(significant_areas)].reset_index())\n",
    "df.where(np.triu(np.ones(df.shape)).astype(np.bool))\n",
    "df.stack().to_csv('control.csv')\n",
    "\n",
    "df = ace.cross_corr(df_fam_cell_count.set_index('area').loc[list(significant_areas)].reset_index())\n",
    "df.where(np.triu(np.ones(df.shape)).astype(np.bool))\n",
    "df.stack().to_csv('fam.csv')\n",
    "\n",
    "df = ace.cross_corr(df_unfam_cell_count.set_index('area').loc[list(significant_areas)].reset_index())\n",
    "df.where(np.triu(np.ones(df.shape)).astype(np.bool))\n",
    "df.stack().to_csv('unfam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:38:42.273856Z",
     "start_time": "2024-09-16T09:38:42.251779Z"
    }
   },
   "outputs": [],
   "source": [
    "corr_matrix_control_ncells = ace.cross_corr(df_control_cell_count)\n",
    "corr_matrix_fam_ncells = ace.cross_corr(df_fam_cell_count)\n",
    "corr_matrix_unfam_ncells = ace.cross_corr(df_unfam_cell_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:38:42.666578Z",
     "start_time": "2024-09-16T09:38:42.276530Z"
    }
   },
   "outputs": [],
   "source": [
    "G_control = create_graph(corr_matrix_control_ncells, volumes=volumes, \n",
    "                         significant_areas=significant_areas, \n",
    "                         corr_threshold=corr_threshold, correlations='one')\n",
    "G_fam = create_graph(corr_matrix_fam_ncells,  volumes=volumes, \n",
    "                         significant_areas=significant_areas, \n",
    "                         corr_threshold=corr_threshold, correlations='one')\n",
    "G_unfam = create_graph(corr_matrix_unfam_ncells,  volumes=volumes, \n",
    "                         significant_areas=significant_areas, \n",
    "                         corr_threshold=corr_threshold, correlations='one')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs of positive correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:38:47.676410Z",
     "start_time": "2024-09-16T09:38:42.668031Z"
    }
   },
   "outputs": [],
   "source": [
    "fig_graph_degrees(G=G_control, title='', volumes=volumes, figsize=(13,7), show_colorbar=False,\n",
    "                 y_lim=25, show_degrees=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:38:52.944438Z",
     "start_time": "2024-09-16T09:38:47.677769Z"
    }
   },
   "outputs": [],
   "source": [
    "fig_graph_degrees(G=G_fam, title='', volumes=volumes, show_colorbar=False, \n",
    "                  show_legend=False, figsize=(12,7), y_lim=25, show_degrees=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:39:20.572215Z",
     "start_time": "2024-09-16T09:39:16.598499Z"
    }
   },
   "outputs": [],
   "source": [
    "fig_graph_degrees(G=G_unfam, title='', volumes=volumes, show_colorbar=False, \n",
    "                  show_legend=False, figsize=(13,7), y_lim=25, show_degrees=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Spring layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:40:10.894333Z",
     "start_time": "2024-09-16T09:40:06.696782Z"
    }
   },
   "outputs": [],
   "source": [
    "show_colorbar=True\n",
    "show_legend=True\n",
    "Gs = [G_control, G_fam, G_unfam]\n",
    "titles=['NOT EXPOSED', 'EXPOSED TO FATHER SCENT MARKS', 'EXPOSED TO CD1 SCENT MARKS']\n",
    "# create tables\n",
    "allen_order = list(volumes[volumes['st_level']==8]['acronym'])\n",
    "df_levels = upls.create_df_levels(volumes, level=8)\n",
    "\n",
    "# create figure\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "edge_cmap = plt.cm.get_cmap('Greys')\n",
    "\n",
    "# Create a gridspec for adding subplots of different sizes\n",
    "axgrid = fig.add_gridspec(1, 3)\n",
    "# plot graph\n",
    "for i, G in enumerate(Gs):\n",
    "    ax = fig.add_subplot(axgrid[i])\n",
    "\n",
    "    order=allen_order\n",
    "\n",
    "    # Plot the network:\n",
    "    # pos = nx.spring_layout(sorted(list(G.nodes()),\n",
    "    #   key = order.index))\n",
    "    pos = nx.spring_layout(G, k=0.4, seed=42)\n",
    "    list_colors = get_colors(G, df_levels, order, volumes=volumes,\n",
    "                            macroareas_to_exclude=['Pons', 'Medulla', 'Cerebellar cortex', 'Cerebellar nuclei'])[0]\n",
    "    nx.draw(G, with_labels=True, node_color=list_colors, \n",
    "            node_size=200,font_size=12, pos=pos, ax=ax, edge_cmap=edge_cmap, width=1,\n",
    "            edge_color=[G[u][v]['weight'] for u, v in G.edges])\n",
    "\n",
    "    # relabel graphs\n",
    "    ax.set_title(titles[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:40:15.967303Z",
     "start_time": "2024-09-16T09:40:15.574390Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, figsize=(10,4), sharex=True, sharey=True)\n",
    "axes[0].set_title('CONTROL')\n",
    "axes[0].hist(list(dict(G_control.degree).values()),\n",
    "            color='steelblue')\n",
    "axes[1].set_title('FAM')\n",
    "axes[1].hist(list(dict(G_fam.degree).values()),\n",
    "            color='darkorange')\n",
    "axes[2].set_title('UNFAM')\n",
    "axes[2].hist(list(dict(G_unfam.degree).values()),\n",
    "            color='green')\n",
    "for i in range(3):\n",
    "    axes[i].set_xlabel('degree')\n",
    "axes[0].set_ylabel('count')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:40:18.193589Z",
     "start_time": "2024-09-16T09:40:18.042012Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxplot = pd.DataFrame({'CONTROL':list(dict(G_control.degree).values()), \n",
    "                           'FAM': list(dict(G_fam.degree).values()), \n",
    "                           'UNFAM':list(dict(G_unfam.degree).values())})\n",
    "fig, ax = plt.subplots(1,1)\n",
    "sns.boxplot(data=df_boxplot, ax=ax)\n",
    "ax.set_xlabel('Condition')\n",
    "ax.set_ylabel('Degree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:40:36.424391Z",
     "start_time": "2024-09-16T09:40:35.925507Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, figsize=(10,4), sharex=True, sharey=True)\n",
    "for i, G in enumerate([G_control, G_fam, G_unfam]):\n",
    "    axes[i].hist([G[u][v]['weight'] for u, v in G.edges],\n",
    "            color='steelblue', bins=50)\n",
    "axes[0].set_title('CONTROL')\n",
    "axes[1].set_title('FAM')\n",
    "axes[2].set_title('UNFAM')\n",
    "for i in range(3):\n",
    "    axes[i].set_xlabel('correlation')\n",
    "axes[0].set_ylabel('count')\n",
    "plt.suptitle('Correlation distribution of significant areas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:40:41.103310Z",
     "start_time": "2024-09-16T09:40:40.513942Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, figsize=(10,4), sharex=True, sharey=True)\n",
    "colors = ['steelblue', 'darkorange', 'green']\n",
    "for i, corr in enumerate([corr_matrix_control_ncells, \n",
    "                          corr_matrix_fam_ncells, \n",
    "                          corr_matrix_unfam_ncells]):\n",
    "    axes[i].hist(corr.mask(np.triu(np.ones(corr.shape)).astype(bool)).stack().values,\n",
    "            color=colors[i], bins=50)\n",
    "axes[0].set_title('CONTROL')\n",
    "axes[1].set_title('FAM')\n",
    "axes[2].set_title('UNFAM')\n",
    "for i in range(3):\n",
    "    axes[i].set_xlabel('correlation')\n",
    "axes[0].set_ylabel('count')\n",
    "plt.suptitle('Correlations of all areas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at betweenness for graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:41:39.532415Z",
     "start_time": "2024-09-16T09:41:39.385108Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,1)\n",
    "graphs=[G_control, G_fam, G_unfam]\n",
    "betweenness_centrality = [nx.betweenness_centrality(G) for G in graphs]\n",
    "df_betweenness_centrality = pd.DataFrame({'CONTROL': [np.mean(list(betweenness_centrality[0].values()))], \n",
    "                                'FAM': [np.mean(list(betweenness_centrality[1].values()))],\n",
    "                                'UNFAM': [np.mean(list(betweenness_centrality[2].values()))]})\n",
    "sns.barplot(data=df_betweenness_centrality, ax=axes)\n",
    "axes.set_ylabel('Average Betweenness Centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:42:43.337624Z",
     "start_time": "2024-09-16T09:42:43.318124Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_betweenness(graphs, volumes):\n",
    "    graphs_titles = ['CONTROL', 'FAM', 'UNFAM']\n",
    "    # create tables\n",
    "    allen_order = list(volumes[volumes['st_level']==8]['acronym'])\n",
    "    df_levels = upls.create_df_levels(volumes,\n",
    "                                     level=8)\n",
    "\n",
    "    # create figure\n",
    "    fig, axes = plt.subplots(3,1, figsize=(10, 8))\n",
    "    plt.subplots_adjust(left=0.25)\n",
    "    for i, G in enumerate(graphs):\n",
    "        colors_dict = get_colors(G, df_levels=df_levels, order=allen_order, volumes=volumes,\n",
    "                                 macroareas_to_exclude=['Pons', \n",
    "                                                        'Medulla', \n",
    "                                                        'Cerebellar cortex', \n",
    "                                                        'Cerebellar nuclei'])[1]\n",
    "        areas = sorted(list(G.nodes()), key = allen_order.index)\n",
    "        betweenness = [nx.betweenness_centrality(G)[area] for area in areas]\n",
    "\n",
    "        # plot degrees\n",
    "        axes[i].bar(x= areas, \n",
    "                height= betweenness)\n",
    "\n",
    "        for idx, color in enumerate(get_colors(G, \n",
    "                                               df_levels=df_levels, \n",
    "                                               order=allen_order,\n",
    "                                               sorting=True,\n",
    "                                               volumes=volumes,\n",
    "                                               macroareas_to_exclude=['Pons', \n",
    "                                                                      'Medulla', \n",
    "                                                                      'Cerebellar cortex', \n",
    "                                                                      'Cerebellar nuclei'])[0]):\n",
    "            axes[i].get_children()[idx].set_color(color) \n",
    "            axes[i].get_children()[idx].set_edgecolor('black')\n",
    "        axes[i].set_title(graphs_titles[i])\n",
    "        axes[i].set_ylabel(\"Betweenness\")\n",
    "        axes[i].set_xlabel('')\n",
    "        if i in [0,1]:\n",
    "            axes[i].set_xticks([])\n",
    "    axes[2].set_xlabel(\"Area\")\n",
    "    axes[2].tick_params(axis='x', labelrotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:42:50.138966Z",
     "start_time": "2024-09-16T09:42:44.686035Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_betweenness(graphs=[G_control, G_fam, G_unfam], volumes=volumes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T14:50:04.523447Z",
     "start_time": "2023-05-30T14:50:04.517677Z"
    }
   },
   "source": [
    "## Look at degree centrality\n",
    "\n",
    "\n",
    "The degree centrality for a node v is the fraction of nodes it is connected to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:43:05.900963Z",
     "start_time": "2024-09-16T09:43:05.744682Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,1)\n",
    "graphs=[G_control, G_fam, G_unfam]\n",
    "degree_centrality = [nx.degree_centrality(G) for G in graphs]\n",
    "df_degree_centrality = pd.DataFrame({'CONTROL': [np.mean(list(degree_centrality[0].values()))], \n",
    "                                'FAM': [np.mean(list(degree_centrality[1].values()))],\n",
    "                                'UNFAM': [np.mean(list(degree_centrality[2].values()))]})\n",
    "sns.barplot(data=df_degree_centrality, ax=axes)\n",
    "axes.set_ylabel('Average degree Centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:43:43.739039Z",
     "start_time": "2024-09-16T09:43:43.725837Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_degree_centrality(graphs, volumes):\n",
    "    graphs_titles = ['CONTROL', 'FAM', 'UNFAM']\n",
    "    # create tables\n",
    "    allen_order = list(volumes[volumes['st_level']==8]['acronym'])\n",
    "    df_levels = upls.create_df_levels(volumes, level=8)\n",
    "\n",
    "    # create figure\n",
    "    fig, axes = plt.subplots(3,1, figsize=(10, 8))\n",
    "    plt.subplots_adjust(left=0.25)\n",
    "    for i, G in enumerate(graphs):\n",
    "        colors_dict = get_colors(G, df_levels=df_levels, order=allen_order, volumes=volumes,\n",
    "                                 macroareas_to_exclude=['Pons', \n",
    "                                                        'Medulla', \n",
    "                                                        'Cerebellar cortex', \n",
    "                                                        'Cerebellar nuclei'])[1]\n",
    "        areas = sorted(list(G.nodes()), key = allen_order.index)\n",
    "        degree_centrality = [nx.degree_centrality(G)[area] for area in areas]\n",
    "\n",
    "        # plot degrees\n",
    "        axes[i].bar(x= areas, \n",
    "                height= degree_centrality)\n",
    "\n",
    "        for idx, color in enumerate(get_colors(G, \n",
    "                                               df_levels=df_levels, \n",
    "                                               order=allen_order,\n",
    "                                               sorting=True,\n",
    "                                               volumes=volumes,\n",
    "                                               macroareas_to_exclude=['Pons', \n",
    "                                                                      'Medulla', \n",
    "                                                                      'Cerebellar cortex', \n",
    "                                                                      'Cerebellar nuclei'])[0]):\n",
    "            axes[i].get_children()[idx].set_color(color) \n",
    "            axes[i].get_children()[idx].set_edgecolor('black')\n",
    "        axes[i].set_title(graphs_titles[i])\n",
    "        axes[i].set_ylabel(\"Degree Centrality\")\n",
    "        axes[i].set_xlabel('')\n",
    "        if i in [0,1]:\n",
    "            axes[i].set_xticks([])\n",
    "    axes[2].set_xlabel(\"Area\")\n",
    "    axes[2].tick_params(axis='x', labelrotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:43:49.069093Z",
     "start_time": "2024-09-16T09:43:44.606315Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_degree_centrality(graphs=[G_control, G_fam, G_unfam], volumes=volumes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficiency\n",
    "\n",
    "The efficiency of a pair of nodes in a graph is the multiplicative inverse of the shortest path distance between the nodes. The average global efficiency of a graph is the average efficiency of all pairs of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:43:56.865482Z",
     "start_time": "2024-09-16T09:43:56.709384Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,1)\n",
    "graphs=[G_control, G_fam, G_unfam]\n",
    "efficiencies = [nx.global_efficiency(G) for G in graphs]\n",
    "df_efficiencies = pd.DataFrame({'CONTROL': [efficiencies[0]], \n",
    "                                'FAM': [efficiencies[1]],\n",
    "                                'UNFAM': [efficiencies[2]]})\n",
    "sns.barplot(data=df_efficiencies, ax=axes)\n",
    "axes.set_ylabel('Global efficiency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T14:04:32.362692Z",
     "start_time": "2023-05-31T14:04:32.353857Z"
    }
   },
   "source": [
    "## Clustering\n",
    "\n",
    "For weighted graphs, there are several ways to define clustering [1]. the one used here is defined as the geometric average of the subgraph edge weights [2],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:44:01.771695Z",
     "start_time": "2024-09-16T09:44:01.633496Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,1)\n",
    "graphs=[G_control, G_fam, G_unfam]\n",
    "clustering = [nx.clustering(G) for G in graphs]\n",
    "df_clustering = pd.DataFrame({'CONTROL': [np.mean(list(clustering[0].values()))], \n",
    "                                'FAM': [np.mean(list(clustering[1].values()))],\n",
    "                                'UNFAM': [np.mean(list(clustering[2].values()))]})\n",
    "sns.barplot(data=df_clustering, ax=axes)\n",
    "axes.set_ylabel('Clustering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:44:32.659860Z",
     "start_time": "2024-09-16T09:44:32.633276Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_clustering(graphs, volumes):\n",
    "    graphs_titles = ['CONTROL', 'FAM', 'UNFAM']\n",
    "    # create tables\n",
    "    allen_order = list(volumes[volumes['st_level']==8]['acronym'])\n",
    "    df_levels = upls.create_df_levels(volumes, level=8)\n",
    "\n",
    "    # create figure\n",
    "    fig, axes = plt.subplots(3,1, figsize=(10, 8))\n",
    "    plt.subplots_adjust(left=0.25)\n",
    "    for i, G in enumerate(graphs):\n",
    "        colors_dict = get_colors(G, df_levels=df_levels, order=allen_order, volumes=volumes,\n",
    "                                 macroareas_to_exclude=['Pons', \n",
    "                                                        'Medulla', \n",
    "                                                        'Cerebellar cortex', \n",
    "                                                        'Cerebellar nuclei'])[1]\n",
    "        areas = sorted(list(G.nodes()), key = allen_order.index)\n",
    "        clustering = [nx.clustering(G)[area] for area in areas]\n",
    "\n",
    "        # plot degrees\n",
    "        axes[i].bar(x= areas, \n",
    "                height= clustering)\n",
    "\n",
    "        for idx, color in enumerate(get_colors(G, \n",
    "                                               df_levels=df_levels, \n",
    "                                               order=allen_order,\n",
    "                                               sorting=True,\n",
    "                                               volumes=volumes,\n",
    "                                               macroareas_to_exclude=['Pons', \n",
    "                                                        'Medulla', \n",
    "                                                        'Cerebellar cortex', \n",
    "                                                        'Cerebellar nuclei'])[0]):\n",
    "            axes[i].get_children()[idx].set_color(color) \n",
    "            axes[i].get_children()[idx].set_edgecolor('black')\n",
    "        axes[i].set_title(graphs_titles[i])\n",
    "        axes[i].set_ylabel(\"Clustering Coefficient\")\n",
    "        axes[i].set_xlabel('')\n",
    "        if i in [0,1]:\n",
    "            axes[i].set_xticks([])\n",
    "    axes[2].set_xlabel(\"Area\")\n",
    "    axes[2].tick_params(axis='x', labelrotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:44:38.187171Z",
     "start_time": "2024-09-16T09:44:33.492908Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_clustering(graphs=[G_control, G_fam, G_unfam], volumes=volumes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rich club coefficient\n",
    "Returns the rich-club coefficient of the graph G.\n",
    "\n",
    "For each degree k, the rich-club coefficient is the ratio of the number of actual to the number of potential edges for nodes with degree greater than k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:44:48.500344Z",
     "start_time": "2024-09-16T09:44:48.366169Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,1)\n",
    "graphs=[G_control, G_fam, G_unfam]\n",
    "rich_club_coefficient = [nx.rich_club_coefficient(G, normalized=False) for G in graphs]\n",
    "df_rich_club_coefficient = pd.DataFrame({'CONTROL': [np.mean(list(rich_club_coefficient[0].values()))], \n",
    "                                'FAM': [np.mean(list(rich_club_coefficient[1].values()))],\n",
    "                                'UNFAM': [np.mean(list(rich_club_coefficient[2].values()))]})\n",
    "sns.barplot(data=df_rich_club_coefficient, ax=axes)\n",
    "axes.set_ylabel('Rich Club Coefficient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small-World coefficient\n",
    "Functions for estimating the small-world-ness of graphs.\n",
    "\n",
    "A small world network is characterized by a small average shortest path length, and a large clustering coefficient.\n",
    "\n",
    "Small-worldness is commonly measured with the coefficient sigma or omega.\n",
    "\n",
    "Both coefficients compare the average clustering coefficient and shortest path length of a given graph against the same quantities for an equivalent random or lattice graph.\n",
    "\n",
    "For more information, see the Wikipedia article on small-world network [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigma\n",
    "\n",
    "Returns the small-world coefficient (sigma) of the given graph.\n",
    "\n",
    "The small-world coefficient is defined as: sigma = C/Cr / L/Lr where C and L are respectively the average clustering coefficient and average shortest path length of G. Cr and Lr are respectively the average clustering coefficient and average shortest path length of an equivalent random graph.\n",
    "\n",
    "A graph is commonly classified as small-world if sigma>1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:38:57.492251Z",
     "start_time": "2024-09-16T09:38:34.743Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1,1)\n",
    "# graphs=[G_control, G_fam, G_unfam]\n",
    "# # calculate the small world coefficient on the largest connected component\n",
    "# sigma = [nx.sigma(G.subgraph(max(nx.connected_components(G), key=len)).copy(), niter=10) for G in graphs]\n",
    "# df_sigma = pd.DataFrame({'CONTROL': [sigma[0]], \n",
    "#                                 'FAM': [sigma[1]],\n",
    "#                                 'UNFAM': [sigma[2]]})\n",
    "# sns.barplot(data=df_sigma, ax=axes)\n",
    "# axes.set_ylabel('Small World Coefficient (sigma)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:38:57.493634Z",
     "start_time": "2024-09-16T09:38:34.745Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1,1)\n",
    "# graphs=[G_control_pls, G_fam_pls, G_unfam_pls]\n",
    "# # calculate the small world coefficient on the largest connected component\n",
    "# sigma = [nx.sigma(G.subgraph(max(nx.connected_components(G), key=len)).copy(), niter=10) for G in graphs]\n",
    "# df_sigma = pd.DataFrame({'CONTROL': [sigma[0]], \n",
    "#                                 'FAM': [sigma[1]],\n",
    "#                                 'UNFAM': [sigma[2]]})\n",
    "# sns.barplot(data=df_sigma, ax=axes)\n",
    "# axes.set_ylabel('Small World Coefficient (sigma)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Omega\n",
    "\n",
    "Returns the small-world coefficient (omega) of a graph\n",
    "\n",
    "The small-world coefficient of a graph G is:\n",
    "\n",
    "omega = Lr/L - C/Cl\n",
    "\n",
    "where C and L are respectively the average clustering coefficient and average shortest path length of G. Lr is the average shortest path length of an equivalent random graph and Cl is the average clustering coefficient of an equivalent lattice graph.\n",
    "\n",
    "The small-world coefficient (omega) measures how much G is like a lattice or a random graph. Negative values mean G is similar to a lattice whereas positive values mean G is a random graph. Values close to 0 mean that G has small-world characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:38:57.494947Z",
     "start_time": "2024-09-16T09:38:34.769Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1,1)\n",
    "# graphs=[G_control, G_fam, G_unfam]\n",
    "# # calculate the small world coefficient on the largest connected component\n",
    "# omega = [nx.omega(G.subgraph(max(nx.connected_components(G), key=len)).copy()) for G in graphs]\n",
    "# df_omega = pd.DataFrame({'CONTROL': [omega[0]], \n",
    "#                                 'FAM': [omega[1]],\n",
    "#                                 'UNFAM': [omega[2]]})\n",
    "# sns.barplot(data=df_omega, ax=axes)\n",
    "# axes.set_ylabel('Small World Coefficient (omega)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:38:57.496150Z",
     "start_time": "2024-09-16T09:38:34.771Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1,1)\n",
    "# graphs=[G_control_pls, G_fam_pls, G_unfam_pls]\n",
    "# # calculate the small world coefficient on the largest connected component\n",
    "# omega = [nx.omega(G.subgraph(max(nx.connected_components(G), key=len)).copy()) for G in graphs]\n",
    "# df_omega = pd.DataFrame({'CONTROL': [omega[0]], \n",
    "#                                 'FAM': [omega[1]],\n",
    "#                                 'UNFAM': [omega[2]]})\n",
    "# sns.barplot(data=df_omega, ax=axes)\n",
    "# axes.set_ylabel('Small World Coefficient (omega)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate within macroarea connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:45:05.574834Z",
     "start_time": "2024-09-16T09:45:05.530231Z"
    }
   },
   "outputs": [],
   "source": [
    "control = ace.cross_corr(df_control_cell_count.set_index('area').loc[list(significant_areas)].reset_index())\n",
    "control = control.where(np.triu(np.ones(control.shape)).astype(np.bool)).stack()\n",
    "\n",
    "fam = ace.cross_corr(df_fam_cell_count.set_index('area').loc[list(significant_areas)].reset_index())\n",
    "fam = fam.where(np.triu(np.ones(fam.shape)).astype(np.bool)).stack()\n",
    "\n",
    "unfam = ace.cross_corr(df_unfam_cell_count.set_index('area').loc[list(significant_areas)].reset_index())\n",
    "unfam = unfam.where(np.triu(np.ones(unfam.shape)).astype(np.bool)).stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:45:06.507774Z",
     "start_time": "2024-09-16T09:45:06.502521Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_crosstab(df_group, significant_areas, df_levels):\n",
    "    df = ace.cross_corr(df_group.set_index('area').loc[list(significant_areas)].reset_index())\n",
    "    df = df.rename_axis(None).rename_axis(None, axis=1)\n",
    "    df1 = df.stack().reset_index()\n",
    "    df1.columns = ['a', 'b', 'corr']\n",
    "    df1 = df1[(df1['corr']>0.75)&(df1['corr']!=1)].reset_index(drop=True)\n",
    "    df1['a_macroarea'] = [df_levels[df_levels['name_area']==area]['name_parent_l5'].item() for area in df1['a']]\n",
    "    df1['b_macroarea'] = [df_levels[df_levels['name_area']==area]['name_parent_l5'].item() for area in df1['b']]\n",
    "    tab = pd.crosstab(df1['a_macroarea'], df1['b_macroarea']).rename_axis(None).rename_axis(None, axis=1)\n",
    "    return tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:45:07.839130Z",
     "start_time": "2024-09-16T09:45:07.445078Z"
    }
   },
   "outputs": [],
   "source": [
    "tab = calculate_crosstab(df_group=df_control_cell_count, \n",
    "                   significant_areas=significant_areas, \n",
    "                   df_levels=df_levels)\n",
    "control = tab[['Isocortex', 'Olfactory areas', 'Cortical subplate', 'Striatum', 'Pallidum', 'Thalamus', 'Hypothalamus',\n",
    "    'Midbrain']].loc[['Isocortex', 'Olfactory areas', 'Cortical subplate', 'Striatum', 'Pallidum', 'Thalamus', 'Hypothalamus',\n",
    "    'Midbrain']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:45:08.797804Z",
     "start_time": "2024-09-16T09:45:08.788937Z"
    }
   },
   "outputs": [],
   "source": [
    "control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:45:09.887042Z",
     "start_time": "2024-09-16T09:45:09.711088Z"
    }
   },
   "outputs": [],
   "source": [
    "tab = calculate_crosstab(df_group=df_fam_cell_count, \n",
    "                   significant_areas=significant_areas, \n",
    "                   df_levels=df_levels)\n",
    "fam = tab[['Isocortex', 'Olfactory areas', 'Cortical subplate', 'Striatum', 'Pallidum', 'Thalamus', 'Hypothalamus',\n",
    "    'Midbrain']].loc[['Isocortex', 'Olfactory areas', 'Cortical subplate', 'Striatum', 'Pallidum', 'Thalamus', 'Hypothalamus',\n",
    "    'Midbrain']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:45:10.773076Z",
     "start_time": "2024-09-16T09:45:10.764931Z"
    }
   },
   "outputs": [],
   "source": [
    "fam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:45:12.095712Z",
     "start_time": "2024-09-16T09:45:11.688819Z"
    }
   },
   "outputs": [],
   "source": [
    "tab = calculate_crosstab(df_group=df_unfam_cell_count, \n",
    "                   significant_areas=significant_areas, \n",
    "                   df_levels=df_levels)\n",
    "unfam = tab[['Isocortex', 'Olfactory areas', 'Cortical subplate', 'Striatum', 'Pallidum', 'Thalamus', 'Hypothalamus',\n",
    "    'Midbrain']].loc[['Isocortex', 'Olfactory areas', 'Cortical subplate', 'Striatum', 'Pallidum', 'Thalamus', 'Hypothalamus',\n",
    "    'Midbrain']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:45:13.022755Z",
     "start_time": "2024-09-16T09:45:13.015970Z"
    }
   },
   "outputs": [],
   "source": [
    "unfam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ClearMap",
   "language": "python",
   "name": "clearmap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
